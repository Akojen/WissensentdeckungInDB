---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Lösungsvorschlag Übungsblatt 10"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier die Namen aller Gruppenmitglieder eintragen!
output: pdf_document
header-includes: 
  - \usepackage{tikz}
  - \usepackage{tikz-qtree}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

### a)
```{r}
set.seed(1234)

idx <- sample(1:nrow(iris), 50)
test <- iris[idx,]
XTest <- test[,1:4]
YTest <- as.numeric(test$Species == "virginica")

train <- iris[-idx,]
XTrain <- train[,1:4]
YTrain <- as.numeric(train$Species == "virginica")

#Gradient descent:

#A5 Eingaben:
weights <- rep(0, 4)
b <- 0
NSteps = 100
Eta = 0.1
#Eta = max( eigen( XTrain )$values )

f <- function(x) {
  return(sigmoid(as.numeric(x) %*% as.numeric(weights)+b))
}

df <- function(x) {
  return(f(x)*(1-f(x)))
}

ell <- function(x, y) {
  return (1/2 * (y - f(x))^2)
}

dell <- function(x, y) {
  err <- (y - f(x))
  return(-err*df(x))
}

sigmoid <- function(z) {
  return(1/(1+exp(-z)))
}

errs <- c()
lastError <- Inf

for(i in 1:NSteps) {
 for (j in 1:nrow(XTrain)){
   
    del <- dell(XTrain[j,], YTrain[j])
    weights <- weights + Eta * -del * XTrain[j,]
    b <- b + Eta * -del
    rss <- ell(XTrain[j,], YTrain[j])
    errs<- c(errs, rss)
 }
  avgErr <- mean(errs)
  cat("Step ", i  ,":avg RSS: ", avgErr , "\n")

  if(lastError < avgErr){
    cat("\n\nGets bigger!!!\n\n")
  }
  
  lastError <- avgErr
  errs <- c()
}

```


### b)

### c)
```{r}
library(neuralnet)

set.seed(1234)

idx <- sample(1:nrow(iris), 50)
test <- iris[idx,]
train <- iris[-idx,]

# Binarize the categorical output
train <- cbind(train, train$Species == 'setosa')
train <- cbind(train, train$Species == 'versicolor')
train <- cbind(train, train$Species == 'virginica')

names(train)[6] <- 'setosa'
names(train)[7] <- 'versicolor'
names(train)[8] <- 'virginica'
``` 

## Aufgabe 2

### a)
```{r}
data = list(
 read.table("blobs.csv", header=TRUE, sep = ","),
 read.table("circles.csv", header=TRUE, sep = ","),
 read.table("moons.csv", header=TRUE, sep = ","),
 read.table("random.csv", header=TRUE, sep = ",")
)

for (dataSet in data) {
    plot(dataSet)
}
```

### b)
```{r}
```

###c) 

## Aufgabe 3

```{r}
daten <- data.frame(Lebenserwartung = c(80.7, 81.8, 80.8, 83.0, 82.1),
                    Kleinkindersterblichkeitsrate = c(3.4, 3.3, 3.7, 2.1, 2.6))
names <- c("Deutschland", "Frankreich", "Irland", "Island", "Schweden")
rownames(daten) = names
```

## a)
```{r}

```

## b)
```{r}

```

## c)
```{r}

```

## d)
```{r}
normDaten <- data.frame(Lebenserwartung = c(rep(0,5)),
                    Kleinkindersterblichkeitsrate = c(rep(0,5)))
rownames(normDaten) = names

#Normalisierung mit mean = 0, var <- 1 (& sd = 1) macht keinen Sinn, da nicht wirklich normalisiert wird ~ Xi / 1.
#Daher: Normalisierung per https://en.wikipedia.org/wiki/Standard_score mit datenspezifischen mean & sd.
meanX <- mean(daten[,1])
meanY <- mean(daten[,2])
sdX <- sd(daten[,1])
sdY <- sd(daten[,2])
for (i in 1:nrow(daten)) {
  normDaten[i,1] <- (daten[i,1] - meanX) / sdX
  normDaten[i,2] <- (daten[i,2] - meanY) / sdY
}

normDist <- dist(normDaten, method = "euclidean", diag = T, upper = T)

singleClust <- hclust(normDist, method = "single")
completeClust <- hclust(normDist, method = "complete")

plot(singleClust)
plot(completeClust)

```

#TODO
Wie viele Cluster würden Sie nun wählen? Vergleichen Sie mit Teilaufgabe a)–c) und erklären Sie eventuelle Unterschiede.

## Aufgabe 4

### a)
```{r}

```

### b)
```{r}

```

### c)
```{r}

```
