---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Lösungsvorschlag Übungsblatt 02"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier Die Nammen aller Gruppenmitglieder eintragen!
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1
```{r}
library(mvtnorm)

```

### a)
Kovarianzmatrix
```{r}


cov <- matrix(c(2,0,0,2),nrow=2)
ev = c(0,0)
```
Erzeugen der Daten
```{r}
b <- rmvnorm(sigma=cov, mean=ev, n=500)
```
### b)
Scatterplot inklusive Höhenlinien
```{r}


intervall <- 0.2
grid <- expand.grid(seq(-4,4,intervall), seq(-4,4,intervall))
norm <- dmvnorm(grid,mean=ev,sigma=cov)

xvec <- seq(-4,4,intervall)

plot(b)
cont <- contour(
  x=xvec,
  y=xvec,
  z=matrix(norm, length(xvec)),
  col="red",
  add=TRUE
)


```


### c)
Randverteilung
```{r}
rand <- b[,1]

```
Histogramm mit Dichte
```{r}

hist(rand, freq=F, main="Beobachtungen von X1", xlab="Beobachtungen")
x <- seq(-4,4, by=0.2)
curve(dnorm( x, mean=0, sd=2), add=T, col="red")

```
Verteilung der Summe
```{r}

sum <- apply(b, 1, sum)

```

Histogramm mit Dichte
```{r}

hist(sum, freq=F, main="Dichte")
x <- seq(-4,4, by=0.2)
curve(dnorm( x, mean=0, sd=2), add=T, col="red")


```

\textcolor{red}{mj: dnorm erwartet die Standardabweichung als Argument nicht die Varianz, daher passt die Kurve in der ersten Grafik nicht zu den Daten 0.5/1}


### d)
Scatterplot inklusive Höhenlinien
```{r}

cov <- matrix(c(2,1.5,1.5,2),nrow=2)

b <- rmvnorm(sigma=cov, mean=ev, n=500)

intervall <- 0.2
grid <- expand.grid(seq(-4,4,intervall), seq(-4,4,intervall))
norm <- dmvnorm(grid,mean=ev,sigma=cov)

xvec <- seq(-4,4,intervall)

plot(b)
cont <- contour(
  x=xvec,
  y=xvec,
  z=matrix(norm, length(xvec)),
  col="red",
  add=TRUE
)


```

\textcolor{red}{mj: Interpretation fehlt 0.5/1}

\textcolor{red}{mj: Gesamt 4/5}


## Aufgabe 3
```{r}
# Laden des RSQLite Paketes
library("RSQLite")

# Verbindung zur pitchfork.sqlite Datenbank herstellen. 
# mydb enthält einen Verweis auf die geöffnete Datenbank und wird im 
# Folgenden für Anfragen an die Datenbank benötigt.
# ACHTUNG: Eventuell muss der Pfad "pitchfork.sqlite" angepasst werden
mydb <- dbConnect(RSQLite::SQLite(), "pitchfork.sqlite")

# Mittels dbListTables kann man sich alle Tabellen in der Datenbank anzeigen lassen
tables <- dbListTables(mydb)
print(tables)

# Mittels dbGetQuery kann man SQLite Anfragen an die Datenbank stellen
content <- dbGetQuery(mydb, 'SELECT * FROM reviews LIMIT 10')
print(content)
```

## a)
\textcolor{red}{SB: 1/1}
```{r}
##Wie viele Tabellen stellt die Datenbank zur Verfügung und wie viele Reviews enthalten diese Tabellen? Welche Attribute sehen Sie?
length(tables)
noReviews <- dbGetQuery(mydb, 'SELECT Count(reviewid) FROM reviews')
print(noReviews)

reviewAttributes <- dbGetQuery(mydb, 'PRAGMA table_info("reviews")')
reviewAttributeNames <- reviewAttributes[,2]
print(reviewAttributeNames)

```


## b)
\textcolor{red}{SB: 1/1}
```{r}
# (1 Punkt) Wie viele Reviews haben the beatles insgesamt erhalten? Wie viele Reviews hat 50
# cent insgesamt erhalten?
# Hinweis: Achten Sie darauf, die Künstlernamen in Anführungszeichen zu schreiben, damit Leerze-
# ichen korrekt erkannt werden.
noBeatlesReviews <- dbGetQuery(mydb, 'SELECT Count(reviewid) FROM reviews WHERE artist = "the beatles"')
print(noBeatlesReviews)
no50centReviews <- dbGetQuery(mydb, 'SELECT Count(reviewid) FROM reviews WHERE artist = "50 cent"')
print(no50centReviews)

```

## c)
\textcolor{red}{SB: 1/1}
```{r}
# (1 Punkt) Welchen durchschnittlichen score haben the beatles bzw. 50 cent bekommen?
avgBeatlesReviews <- dbGetQuery(mydb, 'SELECT avg(score) FROM reviews WHERE artist = "the beatles"')
print(avgBeatlesReviews)
avg50centReviews <- dbGetQuery(mydb, 'SELECT avg(score) FROM reviews WHERE artist = "50 cent"')
print(avg50centReviews) 
```


## d)
\textcolor{red}{SB: 2/2}
\textcolor{red}{SB: Eine "SELECT"-Anweisung im WHERE-Teil ist immer eine langsamere Sache, weil ihr nun für jedes Item in der reviews Datenbank den WHERE-Teil auswertet, d.h. nochmal über die gesamte Tabelle geht (quadratische Laufzeit)}
\textcolor{red}{SB: Ihr könnt entweder SELECT mit SELECT verknüpfen oder direkt das "HAVING"-Keyword benutzen}
```{r}

dbGetQuery(mydb, 'SELECT artist, count(*) FROM reviews GROUP BY artist HAVING count(*) >= 20')
dbGetQuery(mydb, 'SELECT artist FROM (SELECT artist,Count(*) AS c FROM reviews GROUP BY "artist") WHERE c >19')

# (2 Punkt) Geben Sie eine Liste aller Künstler an, für die mindestens 20 Reviews in der Datenbank hinterlegt sind.
list20ReviewArtists <- dbGetQuery(mydb, 'SELECT DISTINCT(rev.artist) FROM reviews rev WHERE (SELECT COUNT(reviewid) FROM reviews WHERE artist = rev.artist) >= 20')
print(list20ReviewArtists)
##Ergebnis = 44 artists. Verarbeitung dauert 2-3 Minuten. Effizintere Lösung?
```

# Aufgabe 4
\textcolor{red}{SB: 2.5/5 - Wieso habt ihr die Daten nicht mit text2vec vorverarbeitet? Wisst ihr überhaupt was für Daten ihr in den Aufruf von apriori benutzt habt?}
```{r}
# Laden des RSQLite Paketes
library("RSQLite")

# Laden des text2vec Paketes
library("text2vec")

# Laden des arules Paketes
library("arules")

# Verbindung zur pitchfork.sqlite Datenbank herstellen. 
# mydb enthält einen Verweis auf die geöffnete Datenbank und wird im 
# Folgenden für Anfragen an die Datenbank benötigt.
# ACHTUNG: Eventuell muss der Pfad "pitchfork.sqlite" angepasst werden
mydb <- dbConnect(RSQLite::SQLite(), "pitchfork.sqlite")

# Mittels dbListTables kann man sich alle Tabellen in der Datenbank anzeigen lassen
tables <- dbListTables(mydb)
print(tables)

# Mittels dbGetQuery kann man SQLite Anfragen an die Datenbank stellen
content <- dbGetQuery(mydb, 'SELECT * FROM reviews LIMIT 10')
print(content)
```

## a)
```{r}
##Passen Sie die SQL Anfrage Q so an, dass alle Reviews der Band Oasis ausgegeben werden. Hierzu müssen Sie die Tabellen content und reviews mit einer entsprechenden WHERE-Klausel verknüpfen.
Q <- dbGetQuery(mydb, 'SELECT * FROM reviews rev
                inner join content cnt on rev.reviewid = cnt.reviewid
                where rev.artist = "oasis"')

##Berechnen Sie die häufigen Mengen mit einem relativem Support von 1%, 10% sowie 25%. Nutzen Sie dazu die Funktion apriori aus dem Paket arules. Schauen Sie sich die Hilfeseite ?apriori zu dieser Funktion an. Wie viele häufige Mengen werden jeweils gefunden? Welche Laufzeit (in Sekunden) können Sie jeweils beobachten?


aprioriHelper <- function(daten, supports) {
  result <- data.frame(matrix(c(1:9),nrow=3,ncol=3))
  colnames(result) <- c("Support", "Anz. hfg. Mengen", "Ausführungszeit")
  for (i in 1:3) {
    startZeit <- Sys.time()
    hfgMenge <- apriori(daten, parameter = list(supp=supports[i], target="frequent itemsets"))
    endZeit <- Sys.time()
    ausfZeit <- endZeit - startZeit
    result[i,1] <- supports[i]
    result[i,2] <- sub(" itemsets", "", sub("set of ", "", capture.output(print(hfgMenge)))) ##extrahiert Anz. der hfg. Mengen aus dem print output des apriori-Ergebnisses
    result[i,3] <- ausfZeit
  }
  return(result)
}

Q <- data.frame(sapply(Q,as.factor)) ## Numerische Daten müssen für Apriori als Faktoren vorkommen

print(aprioriHelper(daten = Q, supports = c(0.01, 0.10, 0.25)))

##Ergebis:
#  Support Anz. hfg. Mengen Ausführungszeit
#1    0.01          932706         1.385227
#2    0.10          932706         1.320865
#3    0.25              39         0.382014

##Führen Sie die gleiche Prozedur auch für alle Reviews mit einem score von 8 oder höher durch.

Q2 <- dbGetQuery(mydb, 'SELECT * FROM reviews rev
                inner join content cnt on rev.reviewid = cnt.reviewid
                where rev.score >= 8')

Q2 <- data.frame(sapply(Q2,as.factor))

print(aprioriHelper(daten = Q2, supports = c(0.01, 0.10, 0.25)))

##Ergebnis:
#  Support Anz. hfg. Mengen Ausführungszeit
#1    0.01            1462         18.03034
#2    0.10              36         17.93734
#3    0.25               7         17.98404


```
## b)
\textcolor{red}{SB: 0/1.5 - Mir ist absolut unklar wie ihr diese Interpretation aufgrund eurer Aufrufe gemacht habt.}
```{r}
##Antwort:
#Wenn man sich die Top 3 der häufigsten Mengen anschaut(*), dann erkennt man z.B. dass Oasis Alben am häufigsten dem Genre Rock angehören und dahingehend ein Zusammenhang besteht (Oasis -> Genre Rock). Dagegen erkennt man im zweiten Datensatz, dass die mit 8/10 und besser bewerteten Alben zumeist nicht mit dem Titel "best new music" (BNM) versehen wurden und dass deren Reviews von sog. "contributors" verfasst wurden. Auch dahingehend besteht ein Zusammenhang (Nicht BNM -> Contributor). Dementsprechend ergibt sich durchaus Interpretationsspielraum in den gefundenen Mengen. Sie lassen z.B. die Interpretation zu, dass die meisten gut bewertete Alben nicht zum Release rezensiert wurden und sich daher nicht für den Titel BNM qualifizieren.
#Wenn man zur Bewerung der Qualität die Angabe "summary of quality measures" im Output des Befehls "summary(x)" zu Rate zieht, so erkennt man mit Zunahme des Supports auch eine Zunahme der "support" und "count" Werte.

```