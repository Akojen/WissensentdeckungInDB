---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 08"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier die Namen aller Gruppenmitglieder eintragen!
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
library("MASS")
library("rpart")
library("rpart.plot")
library("randomForest")
library("mlbench")
        # die Pakete muessen gegebenenfalls installiert werden!
```

## Aufgabe 1

### a)

Daten
```{r}
x = cbind(x1 = c(1, 2, 4, 5, 5, 6, 7, 7, 9, 9), x2 = c(4, 1, 8, 5, 1, 9, 7, 4, 7, 2))
y = c(1, 1, 1, -1, -1, 1, 1, -1, -1, -1)
plot(x[,1], x[,2], col = (y)+2, pch = 16, xlab = expression(x[1]), ylab = expression(x[2]))
legend("topleft", legend = c("-1", "1"), col = c(1, 3), pch = 16, title = "y")
```

Weak Leraner
```{r}
h1 = function(x) if (x[1] <= 3) return(1) else return(-1)
h2 = function(x) if (x[1] <= 8) return(1) else return(-1)
h3 = function(x) if (x[2] > 6) return(1) else return(-1)
```

Initialisierung
```{r}
# https://www.informatik.uni-ulm.de/ni/Lehre/SS05/HauptseminarMustererkennung/ausarbeitungen/Szczot.pdf
m <- nrow(x)
D0 <- rep(1/ m, 10)

```


Iteration 1
```{r}
iteration <- function(Dt, h) {
  train <- apply(x, 1 ,h)
  e1 <- 0
  for (i in 1:nrow(x)) {
    if (train[i] != y[i]) {
      e1 <- e1 + Dt[i]
      
    }
  }
  a <- 1/2 * log((1-e1)/e1)
  
  Z1 <- 0
  for (i in 1:m) {
    Z1 <- Z1 + Dt[i]*exp(-a*y[i]*train[i])
  }
  
  DtPlus1 <- c()
  for (i in 1:m) {
    newElem <- Dt[i]*exp(-a*y[i]*train[i]) / Z1
    DtPlus1 <- c(DtPlus1, newElem)  
  }
  return(list("d"=DtPlus1, "a" = a))
}
Iter1Result <- iteration(D0, h1)
```

Iteration 2
```{r}
Iter2Result <- iteration(Iter1Result$d, h2)
```

Iteration 3
```{r}
Iter3Result <- iteration(Iter2Result$d, h3)
```

### b)
```{r}
xneu = c(6, 3)
```

Vorhersage
```{r}

H <- 0
a <- c(Iter1Result$a,Iter2Result$a,Iter3Result$a)
H <- a[1]*h1(xneu) + a[2]*h2(xneu) + a[3]*h3(xneu)
print(sign(H))

```



## Aufgabe 2
Datensätze erzeugen
```{r}
set.seed(123456789)
test.ind = sample(1:nrow(iris), 10)
iris.test = iris[test.ind, ]
iris.train = iris[-test.ind, ]
data.sets = replicate(5, iris.train[sample(1:nrow(iris.train), 28), c(sample(1:4,2), 5)], simplify = FALSE)

```

### a)

Bäume
```{r}
t1 <- rpart(Species ~ Sepal.Length + Petal.Length,
  	method="class", data=data.sets[[1]])
t2 <- rpart(Species ~ Petal.Width + Sepal.Width,
  	method="class", data=data.sets[[2]])
t3 <- rpart(Species ~ Petal.Length + Sepal.Width,
  	method="class", data=data.sets[[3]])
t4 <- rpart(Species ~ Petal.Length + Petal.Width,
  	method="class", data=data.sets[[4]])
t5 <- rpart(Species ~ Petal.Length + Sepal.Width,
  	method="class", data=data.sets[[5]])

# printcp(t1) # display the results 
# plotcp(t1) # visualize cross-validation results 
# summary(t1) # detailed summary of splits
```
Plots
```{r}
rpart.plot(t1, uniform=TRUE, 
  	main="Baum t1")
rpart.plot(t2, uniform=TRUE, 
  	main="Baum t2")
rpart.plot(t3, uniform=TRUE, 
  	main="Baum t3")
rpart.plot(t4, uniform=TRUE, 
  	main="Baum t4")
rpart.plot(t5, uniform=TRUE, 
  	main="Baum t5")

```



### b)

Vorhersagen
```{r}
##"Betrachten Sie Ihre Bäume als kleinen Zufallswald" -> Problem: Wie kombiniert man einzelne rpart Bäume zu einem Wald?
############### Random Forests (Zufallswälder) Datei, F. 260 ###############
## Ein neues Objekt wird dann von dem Zufallswald so
## klassifiziert, dass es von jedem der berechneten Bäume einmal
## klassifiziert wird und dann der Klasse zugeordnet wird, die die
## meisten Bäume bevorzugt haben (Demokratie im Wald!).

##"Klassifizieren Sie jede Beobachtung aus dem Testdatensatz mit jedem Baum aus Ihrem Wald"
pred1 <- predict(t1, newdata = iris.test, type = "class")
pred2 <- predict(t2, newdata = iris.test, type = "class")
pred3 <- predict(t3, newdata = iris.test, type = "class")
pred4 <- predict(t4, newdata = iris.test, type = "class")
pred5 <- predict(t5, newdata = iris.test, type = "class")
```

Entscheidungen
```{r}
##"Bilden Sie daraus anschließend die Klassenvorhersage für jede Beobachtung"

#-> Kombiniertes Data.frame aller Vorhersagen:
comboPred <- cbind(as.data.frame(pred1), as.data.frame(pred2), as.data.frame(pred3), as.data.frame(pred4), as.data.frame(pred5))

#-> Klassenvorhersage für jede Beobachtung (des Testdatensatzes) ~ "Demokratie im Wald!":
forestClasses <- apply(comboPred,1,function(x) names(which.max(table(x))))
print(forestClasses)
```

Fehlerrate
```{r}
##"Bestimmen Sie die Fehklassifikationsrate"
eR1 <- mean(pred1 != iris.test$Species)
eR2 <- mean(pred2 != iris.test$Species)
eR3 <- mean(pred3 != iris.test$Species)
eR4 <- mean(pred4 != iris.test$Species)
eR5 <- mean(pred5 != iris.test$Species)

comboTreeErr <- mean(c(eR1,eR2,eR3,eR4,eR5))

print(paste0("Die Fehklassifikationsrate beträgt: ", comboTreeErr*100,"%"))

```


### c)

```{r}
set.seed(123456789) # für Reproduzierbarkeit
rf <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris.train, ntree = 5)
predRf <- predict(rf, newdata = iris.test)
errClass <- mean(predRf != iris.test$Species)
print(paste0("Die Fehklassifikationsrate beträgt: ", errClass*100,"%"))
print("Im Gegensatz zur Methode mit kombinierten Einzelbäumen, bei der die Klassen in 40% der Fälle falsch vorhergesagt wurden, gelingt mit randomForest (mit den gegebenen Seed) eine perfekte Klassenvorhersage!!!")
```


```{r}
set.seed(123456789) # für Reproduzierbarkeit
##Passen Sie in einem weiteren Schritt alle Parameter des Random Forests, die die Aufteilung der Daten betreffen, an die Ausgangssituation in dieser Aufgabe an. Wodurch sind mögliche Unterschiede zum Ergebnis aus b) zu erklären?
## --> Zusätzliche Option: sampsize = 28?

rf_new <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris.train, ntree = 5, sampsize = 28)
predRf_new <- predict(rf_new, newdata = iris.test)
errClass <- mean(predRf_new != iris.test$Species)
print(paste0("Die Fehklassifikationsrate beträgt: ", errClass*100,"%"))
print("Standardmäßig scheint die Funktion 'randomForest' 63,2% des Trainingsdatensatzes zu nutzen (hier 89 Samples = ceiling(.632*nrow(iris.train))). Dies scheint wiederum zum Problem des 'Oversamplings' zu führen, was wiederum zu einer perfekten Vorhersage führte. Da hier das Sampling per Argument 'sampsize', vergleichbar mit der Ausgangssituation, auf 28 gesetzt wurde, tritt das Problem nicht mehr auf.")

### https://stats.stackexchange.com/a/24914 
# Increasing the sample size results in a "less random" forest, and so has a tendency to overfit. Decreasing the sample size increases the variation in the individual trees within the forest, preventing overfitting, but usually at the expense of model performance. A useful side-effect is that lower sample sizes reduce the time needed to train the model.
```


## Aufgabe 3

### a)
```{r}
trainAndTest <- function(data, target, p) {
  Data <- data.frame(data, Class=target)
  
  trainIndices <- sample(1:nrow(Data), nrow(Data)*(1-p), replace=F) #leifert immer die gleichen Indizes
  train <- Data[trainIndices,]
  test <- Data[-trainIndices,]
  
  fit <- lda(Class ~ ., Data, subset = trainIndices) # "Variables are collinear" ?! immer bei großem p, also kleinem trainingsdatensatz, fehler oder richtig so?
  p <- predict( fit, test )
  
  testTargets <- Data[-trainIndices, ncol(Data)]
  freq <- table(testTargets == p$class)
  
  acc <- freq[names(freq)=="TRUE"] / nrow(test)
  paste( c("TrainAndTest: ",  acc ) )
}
```

### b)
```{r}
looCV <- function(data, target) {


}
```

### c)
```{r}
kCV <- function(data, target, k = 10) {

}   
```

### d)
```{r}
e0bootstrap <- function(data, target, B) {


}
```

### e)
```{r}
data(Sonar)
set.seed(456)

trainAndTest(Sonar[,-ncol(Sonar)], Sonar[,ncol(Sonar)], 0.25)

```


