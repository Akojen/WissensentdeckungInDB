---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 08"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier die Namen aller Gruppenmitglieder eintragen!
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
library("MASS")
library("rpart")
library("rpart.plot")
library("randomForest")
library("mlbench")
        # die Pakete muessen gegebenenfalls installiert werden!
```

## Aufgabe 1

### a)

Daten
```{r}
x = cbind(x1 = c(1, 2, 4, 5, 5, 6, 7, 7, 9, 9), x2 = c(4, 1, 8, 5, 1, 9, 7, 4, 7, 2))
y = c(1, 1, 1, -1, -1, 1, 1, -1, -1, -1)
plot(x[,1], x[,2], col = (y)+2, pch = 16, xlab = expression(x[1]), ylab = expression(x[2]))
legend("topleft", legend = c("-1", "1"), col = c(1, 3), pch = 16, title = "y")
```

Weak Leraner
```{r}
h1 = function(x) if (x[1] <= 3) return(1) else return(-1)
h2 = function(x) if (x[1] <= 8) return(1) else return(-1)
h3 = function(x) if (x[2] > 6) return(1) else return(-1)
```

Initialisierung
```{r}
# https://www.informatik.uni-ulm.de/ni/Lehre/SS05/HauptseminarMustererkennung/ausarbeitungen/Szczot.pdf
m <- nrow(x)
D1Mtx <- repeat(1 / m, 10)

```


Iteration 1
```{r}
train <- sapply(x, h1)
trainMtx <- matrix(train, nrow = nrow(x), ncol = 2, byrow = F)
H1 <- trainMtx * D1Mtx
e1 <- 0
for (i in nrow(x)) {
  if (H1[i,1] != y[i]) {
    e1 <- e1 + H1[i,1]
  }
  if (H1[i,2] != y[i]) {
    e1 <- e1 + H1[i,2]
  }
}
a1 <- 1/2 * log((1-e1)/e1)

Z1 <- 0
for (i in m/2) {
  Z1 <- D1Mtx[i,]*exp(-a1*y[i]*cbind(h1(x[i,1]), h1(x[i,2])))
}

D2_mtx <- D1Mtx*exp(-a1*y*h1(x)) / Z1
D2 <- c(D2_mtx[,1],D2_mtx[,2])
```

Iteration 2
```{r}

```

Iteration 3
```{r}

```

### b)
```{r}
xneu = c(6, 3)
```

Vorhersage
```{r}

H <- 0
a <- c(a1,a2,a3)
h <- c(h1,h2,h3)
for (i in 1:3) {
  H <- H + a[i]*sapply(xneu, h[i])
}

```



## Aufgabe 2
Datensätze erzeugen
```{r}
set.seed(123456789)
test.ind = sample(1:nrow(iris), 10)
iris.test = iris[test.ind, ]
iris.train = iris[-test.ind, ]
data.sets = replicate(5, iris.train[sample(1:nrow(iris.train), 28), c(sample(1:4,2), 5)], simplify = FALSE)

```

### a)

Bäume
```{r}
t1 <- rpart(Species ~ Sepal.Length + Petal.Length,
  	method="class", data=data.sets[[1]])
t2 <- rpart(Species ~ Petal.Width + Sepal.Width,
  	method="class", data=data.sets[[2]])
t3 <- rpart(Species ~ Petal.Length + Sepal.Width,
  	method="class", data=data.sets[[3]])
t4 <- rpart(Species ~ Petal.Length + Petal.Width,
  	method="class", data=data.sets[[4]])
t5 <- rpart(Species ~ Petal.Length + Sepal.Width,
  	method="class", data=data.sets[[5]])

# printcp(t1) # display the results 
# plotcp(t1) # visualize cross-validation results 
# summary(t1) # detailed summary of splits
```
Plots
```{r}
rpart.plot(t1, uniform=TRUE, 
  	main="Baum t1")
rpart.plot(t2, uniform=TRUE, 
  	main="Baum t2")
rpart.plot(t3, uniform=TRUE, 
  	main="Baum t3")
rpart.plot(t4, uniform=TRUE, 
  	main="Baum t4")
rpart.plot(t5, uniform=TRUE, 
  	main="Baum t5")

```



### b)

Vorhersagen
```{r}

```

Entscheidungen
```{r}

```

Fehlerrate
```{r}
 

```


### c)

```{r}
set.seed(123456789) # für Reproduzierbarkeit

```


```{r}
set.seed(123456789) # für Reproduzierbarkeit

```


## Aufgabe 3

### a)
```{r}
trainAndTest <- function(data, target, p) {

  
}
```

### b)
```{r}
looCV <- function(data, target) {


}
```

### c)
```{r}
kCV <- function(data, target, k = 10) {

}   
```

### d)
```{r}
e0bootstrap <- function(data, target, B) {


}
```

### e)
```{r}
data(Sonar)
set.seed(456)




```


