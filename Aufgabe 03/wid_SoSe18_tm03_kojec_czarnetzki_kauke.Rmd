---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 03"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier Die Nammen aller Gruppenmitglieder eintragen!
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

### a)
a-priori Wahrscheinlichkeiten:
```{r}
aprioriS = 0.25
aprioriUG = 0.75
```


Kostenmatrix
```{r}

costs = matrix(0, nrow = 2, ncol = 2)
colnames(costs) = c("Zubereiten", "Freilassen")
rownames(costs) = c("Schmackhaft", "Ungeniessbar")
```

Werte einfügen
```{r}
costs[1,1] = -30
costs[1,2] = 5
costs[2,1] = 30
costs[2,2] = 5
```

Ausgabe der Kostenmatrix
```{r}
costs
```

### b)

Erwartete Kosten Klasse A:
```{r}
cA = aprioriS*costs[1,1] + aprioriS*costs[1,2]
```

Erwartete Kosten Klasse B:
```{r}
cB = aprioriUG*costs[2,1] + aprioriUG*costs[2,2]
```

Enscheidung der datenunabhängigen Regel:


### c)
Formel aus dem Skript in Abhängigkeit der beobachteten Anzahl Streifen $k$:  
$$
C_j(k) = \sum_{i \in \{A,B\}} π_i · c(1,i) · P(k|i)
$$ 
Formel mit entsprechenden Verteilungen für jedes $k$ auswerten und Entscheidung treffen:

```{r}
C_s = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,1] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,1])
}

C_ug = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,2] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,2])
}

plot(C_s(1:20))
plot(C_ug(1:20))

```


Die Regel besagt: Alle 4 Fische mit mehr als 4 Streifen werden freigelassen.


### d)
Datenunabhängige Regel:
Herleitung
$$
\begin{aligned}
& P(\textrm{Fehler}) \\
= &
\end{aligned}
$$  
oder direkt in R
```{r}

```




Datenabhängige Regel:
Herleitung
$$

$$
oder direkt in R
```{r}

k_un = c()
k_s = c()

for (i in 1:20){
    if (C_s(i) < C_ug(i)) k_s <- c(k_s,i)
    else k_un <- c(k_un, i)
}

print(k_s)
print(k_un)


```
Interpretation:

### e)
Allgemeiner Formel
$$

$$
Datenunabhängige Regel:


Rechnung fuer die Datenabhängige Regel:
```{r}

```

Interpretation:

## Aufgabe 2
```{r}
load("fish.RData")
```

Neue Vorraussetzungen:
```{r}

```


1. NV-Annahme:
```{r}

```
Nur für k = 2 ist ein Fisch schmackhaft
Problem: NV-Annahme nicht unbedingt gerechtfertigt

2. Alte Verteilungsannahme, Parameter schaetzen:
```{r}

```
Hier fuer k = (2, 3)
Verteilugnsannahme scheint hier aus der Literatur gerechtfertigt


3. Relative Haeufigkeiten aus den Daten:
```{r}

```

Problem hier: Manche k wurden nie realisiert, für diese
kann daher keine Entscheidung getroffen werden. Es scheinen noch
zu wenige Beobachtungen zu sein

Sinnvoll erscheint daher Variante 2


## Aufgabe 3
Allgemeines Funktionsgerüst:
```{r}
## mknn - Implementiert das knn Verfahren mit euklidischer Distanz
##        sowohl fuer Klassifikation als auch fuer Regression
## 
## Input:
##   features - data.frame mit den Trainingsdaten
##   y - Vektor mit den wahren Klassenlabeln
##   k - Parameter von knn
##   new.data - dataframe mit neuen Beobachtungen
##
## Ouput:
##   Vektor mit den Klassenlabeln fuer die neuen Beobachtungen
mknn = function(features, y, k, new.data) {
  
  ## Rate ob Klassifikation oder Regression
  classification = is.factor(y)
  result <- c()
  
  ## Vorhersage
  if (classification) {
    ## Entweder den Modalwert bei Klassifikation
    
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        modal <- Mode(y[argsorts[1:k]])
        result <- c(result, as.character(modal))
    }
    
  } else {
    ## Oder den Mittelwert bei Regression
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        reg <- mean(y[argsorts[1:k]])
        result <- c(result, as.numeric(reg))
    }
  }
  return(result)
}

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

```
### a)
Klassifikation
```{r}

indices <- sample(1:150,120, replace=F)
train <- iris[indices,1:4]
traintargets <- iris[indices,5]

testindices <-setdiff(c(1:150),indices)
test <- iris[testindices,1:4]
testtargets <- iris[testindices,5]

classes <- mknn(train, traintargets, 5, test)

fr <- data.frame(testtargets, classes)
colnames(fr) <- c("Soll-Wert", "Regression")

print(fr)

correct <- 0
for (i in 1:length(classes)){
  if(classes[i] == testtargets[i]) correct <- correct+1
}

print( c( "Korrekt:", toString(correct/length(classes) )) )
```

### b)
Regression
```{r}
trainAttr <- c(1,3)
testAttr <- 2

indices <- sample(1:31,20, replace=F)
train <- trees[indices, trainAttr]
traintargets <- trees[indices, testAttr]

testindices <-setdiff(c(1:31), indices)
test <- trees[testindices, trainAttr]
testtargets <- trees[testindices, testAttr]

classes <- mknn(train, traintargets, 3, test)

diffs <- abs(classes-testtargets)
fr <- data.frame( testtargets, classes, diffs )
colnames(fr) <- c("Soll-Wert", "Regression", "Abweichung")

print(fr)
print( c("Durchschnittsabweichung: ", toString( mean(diffs)) ))
```


## Aufgabe 4

### a)
$$
\text{Zu zeigen:} ~\forall B \subseteq C : supp(A \cup B) 	\geq supp(A \cup C) \\
	\equiv supp(A \cup B) \leq max[supp(A), supp(B)] \geq supp(A \cup C) \leq max[supp(A), supp(C)] \\
	\equiv max[supp(A), supp(B)] \geq max[supp(A), supp(C)] \\
	\equiv max[supp(B)] \geq max[supp(C)] \\
	\equiv supp(B) \geq supp(C) ~\forall B \subseteq C
	
$$

### b)
##Itemize funktioniert nicht.
\begin{itemize}
  \item[1)]
  \item[2)]
  \item[3)]
  \item[4)]
  \item[5)]
  \item[6)]
\end{itemize}

### b1)
$$
s(A \rightarrow B) \geq s(A \rightarrow \emptyset) \cdot s(B \rightarrow \emptyset)\\ 
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A \cup \emptyset)}{N} \cdot \frac{s(B \cup \emptyset)}{N}\\
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A)}{N} \cdot \frac{s(B)}{N}\\
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A) \cdot s(B)}{N}\\
  \text{Falsch, da sowohl s(A) als auch s(B) größer/gleich sind als s(A ver. B),} \\
  \text{daher ist deren Produkt echt größer als s(A} \cup \text{B).}
$$
### b2)
$$
c(A \rightarrow B) = c(B \rightarrow A) \Rightarrow s(A) = s(B) \\ \equiv \frac{s(A \cup B)}{s(A)} = \frac{s(B \cup A)}{s(B)} \Rightarrow s(A) = s(B)\\ 
\equiv s(A) = s(B) \Rightarrow s(A) = s(B) \\
~\text{Richtig, da Vereinigung kommutativ ist und wenn die Zähler gleich sind, sind es auch die Nenner.}
$$
### b3)
$$
c(A \rightarrow B) \cdot c(B \rightarrow C) = c(A \rightarrow C) \\
\equiv \frac{s(A \cup B)}{s(A)} \cdot \frac{s(B \cup C)}{s(B)} = \frac{s(A \cup C)}{s(A)} | \cdot s(B) \\
\equiv \frac{s(A \cup B) \cdot s(B \cup C)}{s(A)} = \frac{s(A \cup C) \cdot s(B)}{s(A)} \\
  \text{Richtig. Wenn die Nenner gleich sind, sind es auch die Zähler.} \\
$$
### b4)
$$
c(A \rightarrow B) \geq c(A \rightarrow C) ~\text{mit}~ B \subseteq C \\
\equiv \frac{s(A \cup  B)}{s(A)} \geq \frac{s(A \cup  C)}{s(A)} ~\text{mit}~ s(B) \geq s(C) \\
\equiv \frac{max[s(A),s(B)]}{s(A)} \geq \frac{max[s(A),s(C)]}{s(A)} ~\text{mit}~ s(B) \geq s(C) \\
\text{Richtig aufgrung von}~s(B) \geq s(C).
$$
### b5)
$$
c(\emptyset \rightarrow A) \cdot c(\emptyset \rightarrow B) \geq c(A \rightarrow B) \\
\equiv \frac{s(\emptyset \cup  A)}{s(\emptyset)}  \cdot  \frac{s(\emptyset \cup  B)}{s(\emptyset)} \geq \frac{s(A \cup  B)}{s(A)} \\
\equiv \frac{s(A)}{1}  \cdot \frac{s(B)}{1} \geq \frac{s(A \cup  B)}{s(A)} \\
\equiv s(A)  \cdot s(B) \geq \frac{s(A \cup  B)}{s(A)} \\
  \text{Richtig, da dass Produkt der Supports der Teilmegen von A ver. B,} \\     \text{größer/gleich sein muss als der Support ihrer Vereinigung.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\
$$
### b6)
$$
lift(A \rightarrow B) \geq lift(A \rightarrow C) ~\text{mit}~ B \subseteq C \\
\frac{N \cdot s(A \cap B)}{s(A) \cdot s(B)} \geq \frac{N \cdot s(A \cap C)}{s(A) \cdot s(C)} ~\text{mit}~ s(B) \geq s(C) ~ | \cdot \frac{s(A)}{N}\\
\frac{s(A \cap B)}{s(B)} \geq \frac{s(A \cap C)}{s(C)} ~\text{mit}~ s(B) \geq s(C)\\
\text{Richtig unter der Prämisse, dass die Nenner auch gleich sein können.}
$$
### c)
$$
\text{1)} \\
s(Bier \rightarrow Grillkohle) = \frac{2}{4} = \frac{1}{2} \\
c(Bier \rightarrow Grillkohle) = \frac{\frac{1}{2}}{\frac{3}{4}} = \frac{4}{6} = \frac{2}{3} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*1}{\frac{3}{4}*\frac{1}{2}}=\frac{3}{2} \\
\text{Bier}\rightarrow\text{Grillkohle ist positiv korreliert.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\

\text{2)} \\
s(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{1}{4} \\
c(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{2}{4} = \frac{1}{2} \\
l(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{4*1}{\frac{1}{2}*\frac{3}{4}}=\frac{3}{2} \\
\text{Bier, Grillkohle}\rightarrow\text{Zahnpasta ist positiv korreliert.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\
$$
