---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 03"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier Die Nammen aller Gruppenmitglieder eintragen!
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

### a)
a-priori Wahrscheinlichkeiten:
```{r}
aprioriS = 0.25
aprioriUG = 0.75
```


Kostenmatrix
```{r}

costs = matrix(0, nrow = 2, ncol = 2)
colnames(costs) = c("Zubereiten", "Freilassen")
rownames(costs) = c("Schmackhaft", "Ungeniessbar")
```

Werte einfügen
```{r}
costs[1,1] = -30
costs[1,2] = 5
costs[2,1] = 30
costs[2,2] = 5
```

Ausgabe der Kostenmatrix
```{r}
costs
```

### b)

Erwartete Kosten Klasse A:
```{r}
cA = aprioriS*costs[1,1] + aprioriS*costs[1,2]
print(cA)
```

Erwartete Kosten Klasse B:
```{r}
cB = aprioriUG*costs[2,1] + aprioriUG*costs[2,2]
print(cB)
```

Enscheidung der datenunabhängigen Regel:
Alle Fische werden wieder frei gelassen, weil der Gewinn für die Klasse A geringer ist, als die Kosten für Klasse B. 3/4 der Fische ungenießbar sind und überwiegen damit deutlich.

### c)
Formel aus dem Skript in Abhängigkeit der beobachteten Anzahl Streifen $k$:  
$$
C_j(k) = \sum_{i \in \{A,B\}} π_i · c(1,i) · P(i|k)
$$ 
Formel mit entsprechenden Verteilungen für jedes $k$ auswerten und Entscheidung treffen:

```{r}
C_s = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,1] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,1])
}

C_ug = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,2] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,2])
}

plot(C_s(1:20))
plot(C_ug(1:20))

```


Die Regel besagt: Alle Fische werden freigelassen, außer die mit zwei bzw. drei Streifen.


### d)
Datenunabhängige Regel: Alle Fische werden frei gelassen und damit in die Klasse B eingeordnet.
Herleitung
$$
\begin{aligned}
& P(\textrm{Fehler}) \\
= & π_A\\
= & 0.25
\end{aligned}
$$  
oder direkt in R
```{r}
pFalseDU = aprioriS
```




Datenabhängige Regel: Alle Fische werden freigelassen, außer die mit zwei bzw. drei Streifen.
Herleitung
$$
\begin{aligned}
P(\textrm{Fehler}) =
\begin{cases}
     π_A \cdot P(A|k) & \text{für } k = 1, k \geq 4 \\
     π_B \cdot P(B|k) & \text{für } 2 \leq k \leq 3 \\
   \end{cases}
\end{aligned}
$$
oder direkt in R
```{r}
wrongC <- data.frame(Streifenanzahl = c(1:20), Wahrscheinlichkeit = c(1:20))

P_Wrong_Classification = function(k) {
  if(k == 2 || k == 3) {
    return(aprioriS * dbinom(x=k, size=4, p=0.5))
  } else {
    return(wrongC$Wahrscheinlichkeit[k] <- aprioriUG*dgeom(x=k,prob=0.3))
  }
}

for (i in 1:20){
  wrongC$Wahrscheinlichkeit[i] <- P_Wrong_Classification(i)  
}

print(wrongC, row.names = TRUE)

pFalseDA <- wrongC$Wahrscheinlichkeit[2] + wrongC$Wahrscheinlichkeit[3]
```
Interpretation: Wenn ausschließlich die Fische mit zwei bzw. drei Streifen zubereitet werden, sind dabei immer noch ungefähr 15 Prozent der zubereiteten Fische ungenießbar.

### e)
Allgemeiner Formel
$$
\begin{aligned}
& Verlust_i() \\
= & π_i \cdot P(i|k) \cdot  cost \text{ für } 2 \leq k \leq 3
\end{aligned}
$$
Hinweis: Für die Verlustrechnung wird davon ausgegangen, dass ingesamt 4 Fische gefangen werden. (Ausgehend von der Angabe n = 4 für die Binomialverteilung.) TODO: Brauche ich das überhaupt?

Datenunabhängige Regel: Alle Fische werden frei gelassen und damit in die Klasse B eingeordnet.

Rechnung fuer die Datenunabhängige Regel:
```{r}
lossDU = pFalseDU * costs[1,2]
## Auch wenn wir alle Fische wieder freilassen, so lassen wir in 25% der Fälle schmackhafte Fische frei und tragen somit die erwarteten Angelkosten der Fehlentscheidung.
print(lossDU)
```

Datenabhängige Regel: Alle Fische werden freigelassen, außer die mit zwei bzw. drei Streifen.

Rechnung fuer die Datenabhängige Regel:
```{r}
lossDA = pFalseDA * costs[2,1]
##Trotzdessen, dass wir nun Fische nach der Anzahl der Streifen selektieren, liegen wir in ca. 15% der Fälle immer noch falsch, sodass der erwartete Verlust immer noch ca. 4,7 Euro beträgt.
print(lossDA)
```

Interpretation: Das Ergebnis überrascht, weil die apriori Annahmen über die Fischpopulation eine bessere Entscheidungsgrundlage liefern als die Information aus der Fischliteratur.

## Aufgabe 2
```{r}
load("fish.RData")
```

Neue Vorraussetzungen:
```{r}
size = 1000
```


1. NV-Annahme:
```{r}
quantityS = 0
quantityUG = 0
totalS = 0
totalUG = 0


for (i in 1:quantity){
  if(fishs$type[i] == "tasty") {
    quantityS = quantityS + 1
    totalS = totalS + fishs$strips[i]
  } else {
    quantityUG = quantityUG + 1
    totalUG = totalUG + fishs$strips[i]
  }
}

#Arithmetisches Mittel
averageS = totalS / quantityS
averageUG = totalUG / quantityUG
print(averageS)
print(averageUG)

varianceS = 0
varianceUG = 0

for (i in 1:quantity){
  if(fishs$type[i] == "tasty") {
    varianceS = varianceS + (fishs$strips[i] - averageS) * (fishs$strips[i] - averageS)
  } else {
    varianceUG = varianceUG + (fishs$strips[i] - averageUG) * (fishs$strips[i] - averageUG)
  }
}
  
#Standardabweichung
deviationS = sqrt((1/(quantityS - 1)) * varianceS)
deviationUG = sqrt((1/(quantityUG - 1)) * varianceUG)
print(deviationS)
print(deviationUG)

#Normalverteilung
normalDistributionS = rnorm(n = 1000, mean = averageS, sd = deviationS)
normalDistributionUG = rnorm(n = 1000, mean = averageUG, sd = deviationUG)
plot(normalDistributionS)
plot(normalDistributionUG)
```
Nur für k = 2 ist ein Fisch schmackhaft
Problem: NV-Annahme nicht unbedingt gerechtfertigt

2. Alte Verteilungsannahme, Parameter schaetzen:
```{r}
total = length(fishs$strips)
#dbinom(x=?, size=1000, p=1)
#dbinom(x=?, size=1000, p=1/total
#dgeom(x=?, prob=1/(1+total))

```
Hier fuer k = (2, 3)
Verteilugnsannahme scheint hier aus der Literatur gerechtfertigt


3. Relative Haeufigkeiten aus den Daten:
```{r}

```

Problem hier: Manche k wurden nie realisiert, für diese
kann daher keine Entscheidung getroffen werden. Es scheinen noch
zu wenige Beobachtungen zu sein

Sinnvoll erscheint daher Variante 2


## Aufgabe 3
Allgemeines Funktionsgerüst:
```{r}
## mknn - Implementiert das knn Verfahren mit euklidischer Distanz
##        sowohl fuer Klassifikation als auch fuer Regression
## 
## Input:
##   features - data.frame mit den Trainingsdaten
##   y - Vektor mit den wahren Klassenlabeln
##   k - Parameter von knn
##   new.data - dataframe mit neuen Beobachtungen
##
## Ouput:
##   Vektor mit den Klassenlabeln fuer die neuen Beobachtungen
mknn = function(features, y, k, new.data) {
  
  ## Rate ob Klassifikation oder Regression
  classification = is.factor(y)
  result <- c()
  
  ## Vorhersage
  if (classification) {
    ## Entweder den Modalwert bei Klassifikation
    
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        modal <- Mode(y[argsorts[1:k]])
        result <- c(result, as.character(modal))
    }
    
  } else {
    ## Oder den Mittelwert bei Regression
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        reg <- mean(y[argsorts[1:k]])
        result <- c(result, as.numeric(reg))
    }
  }
  return(result)
}

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

```
### a)
Klassifikation
```{r}

indices <- sample(1:150,120, replace=F)
train <- iris[indices,1:4]
traintargets <- iris[indices,5]

testindices <-setdiff(c(1:150),indices)
test <- iris[testindices,1:4]
testtargets <- iris[testindices,5]

classes <- mknn(train, traintargets, 5, test)

fr <- data.frame(testtargets, classes)
colnames(fr) <- c("Soll-Wert", "Regression")

print(fr)

correct <- 0
for (i in 1:length(classes)){
  if(classes[i] == testtargets[i]) correct <- correct+1
}

print( c( "Korrekt:", toString(correct/length(classes) )) )
```

### b)
Regression
```{r}
trainAttr <- c(1,3)
testAttr <- 2

indices <- sample(1:31,20, replace=F)
train <- trees[indices, trainAttr]
traintargets <- trees[indices, testAttr]

testindices <-setdiff(c(1:31), indices)
test <- trees[testindices, trainAttr]
testtargets <- trees[testindices, testAttr]

classes <- mknn(train, traintargets, 3, test)

diffs <- abs(classes-testtargets)
fr <- data.frame( testtargets, classes, diffs )
colnames(fr) <- c("Soll-Wert", "Regression", "Abweichung")

print(fr)
print( c("Durchschnittsabweichung: ", toString( mean(diffs)) ))
```


## Aufgabe 4

### a)
$$
\text{Zu zeigen:} ~\forall B \subseteq C : supp(A \cup B) 	\geq supp(A \cup C) \\
	\equiv supp(A \cup B) \leq max[supp(A), supp(B)] \geq supp(A \cup C) \leq max[supp(A), supp(C)] \\
	\equiv max[supp(A), supp(B)] \geq max[supp(A), supp(C)] \\
	\equiv max[supp(B)] \geq max[supp(C)] \\
	\equiv supp(B) \geq supp(C) ~\forall B \subseteq C
	
$$

### b)
##Itemize funktioniert nicht.
\begin{itemize}
  \item[1)]
  \item[2)]
  \item[3)]
  \item[4)]
  \item[5)]
  \item[6)]
\end{itemize}

### b1)
$$
s(A \rightarrow B) \geq s(A \rightarrow \emptyset) \cdot s(B \rightarrow \emptyset)\\ 
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A \cup \emptyset)}{N} \cdot \frac{s(B \cup \emptyset)}{N}\\
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A)}{N} \cdot \frac{s(B)}{N}\\
  \equiv \frac{s(A \cup B)}{N} \geq \frac{s(A) \cdot s(B)}{N}\\
  \text{Falsch, da sowohl s(A) als auch s(B) größer/gleich sind als s(A ver. B),} \\
  \text{daher ist deren Produkt echt größer als s(A} \cup \text{B).}
$$
### b2)
$$
c(A \rightarrow B) = c(B \rightarrow A) \Rightarrow s(A) = s(B) \\ \equiv \frac{s(A \cup B)}{s(A)} = \frac{s(B \cup A)}{s(B)} \Rightarrow s(A) = s(B)\\ 
\equiv s(A) = s(B) \Rightarrow s(A) = s(B) \\
~\text{Richtig, da Vereinigung kommutativ ist und wenn die Zähler gleich sind, sind es auch die Nenner.}
$$
### b3)
$$
c(A \rightarrow B) \cdot c(B \rightarrow C) = c(A \rightarrow C) \\
\equiv \frac{s(A \cup B)}{s(A)} \cdot \frac{s(B \cup C)}{s(B)} = \frac{s(A \cup C)}{s(A)} | \cdot s(B) \\
\equiv \frac{s(A \cup B) \cdot s(B \cup C)}{s(A)} = \frac{s(A \cup C) \cdot s(B)}{s(A)} \\
  \text{Richtig. Wenn die Nenner gleich sind, sind es auch die Zähler.} \\
$$
### b4)
$$
c(A \rightarrow B) \geq c(A \rightarrow C) ~\text{mit}~ B \subseteq C \\
\equiv \frac{s(A \cup  B)}{s(A)} \geq \frac{s(A \cup  C)}{s(A)} ~\text{mit}~ s(B) \geq s(C) \\
\equiv \frac{max[s(A),s(B)]}{s(A)} \geq \frac{max[s(A),s(C)]}{s(A)} ~\text{mit}~ s(B) \geq s(C) \\
\text{Richtig aufgrung von}~s(B) \geq s(C).
$$
### b5)
$$
c(\emptyset \rightarrow A) \cdot c(\emptyset \rightarrow B) \geq c(A \rightarrow B) \\
\equiv \frac{s(\emptyset \cup  A)}{s(\emptyset)}  \cdot  \frac{s(\emptyset \cup  B)}{s(\emptyset)} \geq \frac{s(A \cup  B)}{s(A)} \\
\equiv \frac{s(A)}{1}  \cdot \frac{s(B)}{1} \geq \frac{s(A \cup  B)}{s(A)} \\
\equiv s(A)  \cdot s(B) \geq \frac{s(A \cup  B)}{s(A)} \\
  \text{Richtig, da dass Produkt der Supports der Teilmegen von A ver. B,} \\     \text{größer/gleich sein muss als der Support ihrer Vereinigung.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\
$$
### b6)
$$
lift(A \rightarrow B) \geq lift(A \rightarrow C) ~\text{mit}~ B \subseteq C \\
\frac{N \cdot s(A \cap B)}{s(A) \cdot s(B)} \geq \frac{N \cdot s(A \cap C)}{s(A) \cdot s(C)} ~\text{mit}~ s(B) \geq s(C) ~ | \cdot \frac{s(A)}{N}\\
\frac{s(A \cap B)}{s(B)} \geq \frac{s(A \cap C)}{s(C)} ~\text{mit}~ s(B) \geq s(C)\\
\text{Richtig unter der Prämisse, dass die Nenner auch gleich sein können.}
$$
### c)
$$
\text{1)} \\
s(Bier \rightarrow Grillkohle) = \frac{2}{4} = \frac{1}{2} \\
c(Bier \rightarrow Grillkohle) = \frac{\frac{1}{2}}{\frac{3}{4}} = \frac{4}{6} = \frac{2}{3} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*1}{\frac{3}{4}*\frac{1}{2}}=\frac{3}{2} \\
\text{Bier}\rightarrow\text{Grillkohle ist positiv korreliert.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\

\text{2)} \\
s(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{1}{4} \\
c(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{2}{4} = \frac{1}{2} \\
l(Bier,Grillkohle \rightarrow Zahnpasta) = \frac{4*1}{\frac{1}{2}*\frac{3}{4}}=\frac{3}{2} \\
\text{Bier, Grillkohle}\rightarrow\text{Zahnpasta ist positiv korreliert.} \\
\text{(Unter der Annahme:} ~s(\emptyset)=1)\\
$$
