---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 03"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier Die Nammen aller Gruppenmitglieder eintragen!
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

### a)
a-priori Wahrscheinlichkeiten:
```{r}
aprioriS = 0.25
aprioriUG = 0.75
```


Kostenmatrix
```{r}

costs = matrix(0, nrow = 2, ncol = 2)
colnames(costs) = c("Zubereiten", "Freilassen")
rownames(costs) = c("Schmackhaft", "Ungeniessbar")
```

Werte einfügen
```{r}
costs[1,1] = -30
costs[1,2] = 5
costs[2,1] = 30
costs[2,2] = 5
```

Ausgabe der Kostenmatrix
```{r}
costs
```

### b)

Erwartete Kosten Klasse A:
```{r}
cA = aprioriS*costs[1,1] + aprioriS*costs[1,2]
```

Erwartete Kosten Klasse B:
```{r}
cB = aprioriUG*costs[2,1] + aprioriUG*costs[2,2]
```

Enscheidung der datenunabhängigen Regel:


### c)
Formel aus dem Skript in Abhängigkeit der beobachteten Anzahl Streifen $k$:  
$$
C_j(k) = \sum_{i \in \{A,B\}} π_i · c(1,i) · P(k|i)
$$ 
Formel mit entsprechenden Verteilungen für jedes $k$ auswerten und Entscheidung treffen:

```{r}
C_s = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,1] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,1])
}

C_ug = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,2] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,2])
}

plot(C_s(1:20))
plot(C_ug(1:20))

```


Die Regel besagt: Alle 4 Fische mit mehr als 4 Streifen werden freigelassen.


### d)
Datenunabhängige Regel:
Herleitung
$$
\begin{aligned}
& P(\textrm{Fehler}) \\
= &
\end{aligned}
$$  
oder direkt in R
```{r}

```




Datenabhängige Regel:
Herleitung
$$

$$
oder direkt in R
```{r}

k_un = c()
k_s = c()

for (i in 1:20){
    if (C_s(i) < C_ug(i)) k_s <- c(k_s,i)
    else k_un <- c(k_un, i)
}

print(k_s)
print(k_un)


```
Interpretation:

### e)
Allgemeiner Formel
$$

$$
Datenunabhängige Regel:


Rechnung fuer die Datenabhängige Regel:
```{r}

```

Interpretation:

## Aufgabe 2
```{r}
load("fish.RData")
```

Neue Vorraussetzungen:
```{r}

```


1. NV-Annahme:
```{r}

```
Nur für k = 2 ist ein Fisch schmackhaft
Problem: NV-Annahme nicht unbedingt gerechtfertigt

2. Alte Verteilungsannahme, Parameter schaetzen:
```{r}

```
Hier fuer k = (2, 3)
Verteilugnsannahme scheint hier aus der Literatur gerechtfertigt


3. Relative Haeufigkeiten aus den Daten:
```{r}

```

Problem hier: Manche k wurden nie realisiert, für diese
kann daher keine Entscheidung getroffen werden. Es scheinen noch
zu wenige Beobachtungen zu sein

Sinnvoll erscheint daher Variante 2


## Aufgabe 3
Allgemeines Funktionsgerüst:
```{r}
## mknn - Implementiert das knn Verfahren mit euklidischer Distanz
##        sowohl fuer Klassifikation als auch fuer Regression
## 
## Input:
##   features - data.frame mit den Trainingsdaten
##   y - Vektor mit den wahren Klassenlabeln
##   k - Parameter von knn
##   new.data - dataframe mit neuen Beobachtungen
##
## Ouput:
##   Vektor mit den Klassenlabeln fuer die neuen Beobachtungen
mknn = function(features, y, k, new.data) {
  
  ## Rate ob Klassifikation oder Regression
  classification = is.factor(y)
  result <- c()
  
  ## Vorhersage
  if (classification) {
    ## Entweder den Modalwert bei Klassifikation
    
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        modal <- Mode(y[argsorts[1:k]])
        result <- c(result, as.character(modal))
    }
    
  } else {
    ## Oder den Mittelwert bei Regression
    for (i in 1:nrow(new.data)){
        d <- dist(rbind(new.data[i,], features))
        dists <- d[1:nrow(features)]
        argsorts <- order(dists)
        reg <- mean(y[argsorts[1:k]])
        result <- c(result, as.numeric(reg))
    }
  }
  return(result)
}

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

```
### a)
Klassifikation
```{r}

indices <- sample(1:150,120, replace=F)
train <- iris[indices,1:4]
traintargets <- iris[indices,5]

testindices <-setdiff(c(1:150),indices)
test <- iris[testindices,1:4]
testtargets <- iris[testindices,5]

classes <- mknn(train, traintargets, 5, test)

fr <- data.frame(testtargets, classes)
colnames(fr) <- c("Soll-Wert", "Regression")

print(fr)

correct <- 0
for (i in 1:length(classes)){
  if(classes[i] == testtargets[i]) correct <- correct+1
}

print( c( "Korrekt:", toString(correct/length(classes) )) )
```

### b)
Regression
```{r}
trainAttr <- c(1,3)
testAttr <- 2

indices <- sample(1:31,20, replace=F)
train <- trees[indices, trainAttr]
traintargets <- trees[indices, testAttr]

testindices <-setdiff(c(1:31), indices)
test <- trees[testindices, trainAttr]
testtargets <- trees[testindices, testAttr]

classes <- mknn(train, traintargets, 3, test)

diffs <- abs(classes-testtargets)
fr <- data.frame( testtargets, classes, diffs )
colnames(fr) <- c("Soll-Wert", "Regression", "Abweichung")

print(fr)
print( c("Durchschnittsabweichung: ", toString( mean(diffs)) ))
```



## Aufgabe 4
## Aufgabe 4

### a)
$$
\text{Zu zeigen:}\\
\forall B \subseteq C : supp(A \cup B) 	\geq supp(A \cup C) \\
	\equiv supp(A \cup B) \leq max[supp(A), supp(B)] \geq \\ supp(A \cup C) \leq max[supp(A), supp(C)] \\
	\equiv max[supp(A), supp(B)] \geq max[supp(A), supp(C)] \\
	\equiv max[supp(B)] \geq max[supp(C)] \\
	\equiv supp(B) \geq supp(C) \\
	\equiv B \subseteq C

$$
### b)

### b)
\begin{itemize}
  \item[1)]
  \item[2)]
  \item[3)]
  \item[4)]
  \item[5)]
  \item[6)]
\end{itemize}

### c)
$$
\text{1)} \\
supp(Bier \rightarrow Grillkohle) = \frac{1}{2} \\
conf(Bier \rightarrow Grillkohle) = \frac{2}{3} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*?}{\frac{3}{4}*\frac{1}{2}}=? \\

\text{2)} \\
supp(Bier,Grillkohle \rightarrow Zahnpaste) = \frac{1}{4} \\
conf(Bier,Grillkohle \rightarrow Zahnpaste) = \frac{1}{2} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*?}{\frac{3}{4}*\frac{1}{2}}=? \\
$$
