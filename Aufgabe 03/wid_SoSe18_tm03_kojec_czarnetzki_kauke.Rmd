---
title: "Wissensentdeckung in Datenbanken SoSe 2018"
subtitle: "Übungsblatt 03"
author: "Alexander Kojen, Robin Czarnetzki, Jonas Kauke"  # Hier Die Nammen aller Gruppenmitglieder eintragen!
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # Code wird ausgegeben
```
## Aufgabe 1

### a)
a-priori Wahrscheinlichkeiten:
```{r}
aprioriS = 0.25
aprioriUG = 0.75
```


Kostenmatrix
```{r}

costs = matrix(0, nrow = 2, ncol = 2)
colnames(costs) = c("Zubereiten", "Freilassen")
rownames(costs) = c("Schmackhaft", "Ungeniessbar")
```

Werte einfügen
```{r}
costs[1,1] = -30
costs[1,2] = 5
costs[2,1] = 30
costs[2,2] = 5
```

Ausgabe der Kostenmatrix
```{r}
costs
```

### b)

Erwartete Kosten Klasse A:
```{r}
cA = aprioriS*costs[1,1] + aprioriS*costs[1,2]
```

Erwartete Kosten Klasse B:
```{r}
cB = aprioriUG*costs[2,1] + aprioriUG*costs[2,2]
```

Enscheidung der datenunabhängigen Regel:


### c)
Formel aus dem Skript in Abhängigkeit der beobachteten Anzahl Streifen $k$:  
$$
C_j(k) = \sum_{i \in \{A,B\}} π_i · c(1,i) · P(k|i)
$$ 
Formel mit entsprechenden Verteilungen für jedes $k$ auswerten und Entscheidung treffen:

```{r}
C_s = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,1] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,1])
}

C_ug = function(k) {
  (aprioriS*dbinom(x=k, size=4, p=0.5)*costs[1,2] + aprioriUG*dgeom(x=k,prob=0.3)*costs[2,2])
}

plot(C_s(1:20))
plot(C_ug(1:20))

```


Die Regel besagt: Alle 4 Fische mit mehr als 4 Streifen werden freigelassen.


### d)
Datenunabhängige Regel:
Herleitung
$$
\begin{aligned}
& P(\textrm{Fehler}) \\
= &
\end{aligned}
$$  
oder direkt in R
```{r}

```




Datenabhängige Regel:
Herleitung
$$

$$
oder direkt in R
```{r}

k_un = c()
k_s = c()

for (i in 1:20){
    if (C_s(i) < C_ug(i)) k_s <- c(k_s,i)
    else k_un <- c(k_un, i)
}

print(k_s)
print(k_un)


```
Interpretation:

### e)
Allgemeiner Formel
$$

$$
Datenunabhängige Regel:


Rechnung fuer die Datenabhängige Regel:
```{r}

```

Interpretation:

## Aufgabe 2
```{r}
load("fish.RData")
```

Neue Vorraussetzungen:
```{r}

```


1. NV-Annahme:
```{r}

```
Nur für k = 2 ist ein Fisch schmackhaft
Problem: NV-Annahme nicht unbedingt gerechtfertigt

2. Alte Verteilungsannahme, Parameter schaetzen:
```{r}

```
Hier fuer k = (2, 3)
Verteilugnsannahme scheint hier aus der Literatur gerechtfertigt


3. Relative Haeufigkeiten aus den Daten:
```{r}

```

Problem hier: Manche k wurden nie realisiert, für diese
kann daher keine Entscheidung getroffen werden. Es scheinen noch
zu wenige Beobachtungen zu sein

Sinnvoll erscheint daher Variante 2


## Aufgabe 3
Allgemeines Funktionsgerüst:
```{r}
## mknn - Implementiert das knn Verfahren mit euklidischer Distanz
##        sowohl fuer Klassifikation als auch fuer Regression
## 
## Input:
##   features - data.frame mit den Trainingsdaten
##   y - Vektor mit den wahren Klassenlabeln
##   k - Parameter von knn
##   new.data - dataframe mit neuen Beobachtungen
##
## Ouput:
##   Vektor mit den Klassenlabeln fuer die neuen Beobachtungen
mknn = function(features, y, k, new.data) {
  
  ## Rate ob Klassifikation oder Regression
  classification = is.factor(y)
  
  print(new.data)
  
  
  ## Vorhersage
  if (classification) {
    ## Entweder den Modalwert bei Klassifikation
    for (i in 1:nrow(new.data)){
      for(j in 1:nrow(features[i,])){
        d <- dist(rbind(features[j,],new.data[i,]))
        print(d)
      }
    }
    
  } else {
    ## Oder den Mittelwert bei Regression
    
  }
}
```
### a)
Klassifikation
```{r}

indices <- sample(1:150,120, replace=F)
train <- iris[indices,1:4]
target <- iris[indices,5]
test <- iris[setdiff(c(1:150),indices),1:4]

mknn(train,target,1,test)

```

### b)
Regression
```{r}

```



## Aufgabe 4
## Aufgabe 4

### a)
$$
\text{Zu zeigen:}\\
\forall B \subseteq C : supp(A \cup B) 	\geq supp(A \cup C) \\
	\equiv supp(A \cup B) \leq max[supp(A), supp(B)] \geq \\ supp(A \cup C) \leq max[supp(A), supp(C)] \\
	\equiv max[supp(A), supp(B)] \geq max[supp(A), supp(C)] \\
	\equiv max[supp(B)] \geq max[supp(C)] \\
	\equiv supp(B) \geq supp(C) \\
	\equiv B \subseteq C

$$
### b)

### b)
\begin{itemize}
  \item[1)]
  \item[2)]
  \item[3)]
  \item[4)]
  \item[5)]
  \item[6)]
\end{itemize}

### c)
$$
\text{1)} \\
supp(Bier \rightarrow Grillkohle) = \frac{1}{2} \\
conf(Bier \rightarrow Grillkohle) = \frac{2}{3} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*?}{\frac{3}{4}*\frac{1}{2}}=? \\

\text{2)} \\
supp(Bier,Grillkohle \rightarrow Zahnpaste) = \frac{1}{4} \\
conf(Bier,Grillkohle \rightarrow Zahnpaste) = \frac{1}{2} \\
lift(Bier \rightarrow Grillkohle) = \frac{4*?}{\frac{3}{4}*\frac{1}{2}}=? \\
$$
